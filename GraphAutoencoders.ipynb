{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXbQArE97n-I",
        "outputId": "48974dae-656b-4064-a450-f26818fcb1ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deepchem\n",
            "  Downloading deepchem-2.7.1-py3-none-any.whl (693 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.2/693.2 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.2.2)\n",
            "Collecting scipy<1.9 (from deepchem)\n",
            "  Downloading scipy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rdkit (from deepchem)\n",
            "  Downloading rdkit-2023.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2022.7.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit->deepchem) (8.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deepchem) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->deepchem) (1.16.0)\n",
            "Installing collected packages: scipy, rdkit, deepchem\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.10.1\n",
            "    Uninstalling scipy-1.10.1:\n",
            "      Successfully uninstalled scipy-1.10.1\n",
            "Successfully installed deepchem-2.7.1 rdkit-2023.3.1 scipy-1.8.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.8.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.27.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910459 sha256=26d38002a5cd1bd5b115ef8c36d1b6b99f5fd7d0805e97c3869b345131ad2182\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install deepchem\n",
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Dataset, Data\n",
        "import numpy as np \n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import deepchem as dc\n",
        "from rdkit import Chem\n",
        "import torch.nn as nn\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import GAE\n",
        "from torch_geometric.data import Data, download_url, extract_gz\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch_geometric.transforms as T"
      ],
      "metadata": {
        "id": "4zKJC2YK8A8j"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'http://snap.stanford.edu/biodata/datasets/10012/files/DG-AssocMiner_miner-disease-gene.tsv.gz'\n",
        "extract_gz(download_url(url, '.'), '.')\n",
        "\n",
        "data_path = \"./DG-AssocMiner_miner-disease-gene.tsv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7xPBTXNxnkf",
        "outputId": "8b1b1e71-5e00-4e41-cf84-97f5505d226d"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading http://snap.stanford.edu/biodata/datasets/10012/files/DG-AssocMiner_miner-disease-gene.tsv.gz\n",
            "Extracting ./DG-AssocMiner_miner-disease-gene.tsv.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(data_path, sep=\"\\t\")\n",
        "print(df.head(), '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DbeXih-yO66",
        "outputId": "61280ddf-466a-4773-99d0-6df013cf26e5"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  # Disease ID              Disease Name  Gene ID\n",
            "0     C0036095  Salivary Gland Neoplasms     1462\n",
            "1     C0036095  Salivary Gland Neoplasms     1612\n",
            "2     C0036095  Salivary Gland Neoplasms      182\n",
            "3     C0036095  Salivary Gland Neoplasms     2011\n",
            "4     C0036095  Salivary Gland Neoplasms     2019 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_node_mapping(datafile_path, index_col, offset=0):\n",
        "  \"\"\"\n",
        "  Maps each distinct node to a unique integer index.\n",
        "\n",
        "  Args: datafile_path, string name of the tsv file containing the graph data\n",
        "        index_col, string name of the column containing the nodes of concern\n",
        "        offset, amount to shift the generated indexes by\n",
        "  Returns: the mapping from node name to integer index\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(datafile_path, index_col=index_col, sep=\"\\t\")\n",
        "  mapping = {index_id: i + offset for i, index_id in enumerate(df.index.unique())}\n",
        "  return mapping"
      ],
      "metadata": {
        "id": "QBruxamAyRuT"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_edge_list(datafile_path, src_col, src_mapping, dst_col, dst_mapping):\n",
        "  \"\"\"\n",
        "  Given node mappings, returns edge list in terms of node integer indices.\n",
        "\n",
        "  Args: datafile_path, string name of the tsv file containing the graph data\n",
        "        src_col, string name of the column corresponding to source nodes\n",
        "        src_mapping, mapping from source node name to integer index\n",
        "  Returns: the mapping from node name to integer index\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(datafile_path, sep=\"\\t\")\n",
        "  src_nodes = [src_mapping[index] for index in df[src_col]]\n",
        "  dst_nodes = [dst_mapping[index] for index in df[dst_col]]\n",
        "  edge_index = torch.tensor([src_nodes, dst_nodes])\n",
        "  return edge_index"
      ],
      "metadata": {
        "id": "ygedMgYjzeJD"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_data(datafile_path, num_features=1):\n",
        "  \"\"\"\n",
        "  Given a tsv file specifying disease-gene interactions, index the nodes and\n",
        "  construct a Data object.\n",
        "  \"\"\"\n",
        "  # Get disease node mapping and gene node mapping.\n",
        "  # Each node type has its own set of integer ids.\n",
        "  dz_col, gene_col = \"# Disease ID\", \"Gene ID\"\n",
        "  dz_mapping = load_node_mapping(datafile_path, dz_col, offset=0)\n",
        "  gene_mapping = load_node_mapping(datafile_path, gene_col, offset=519)\n",
        "\n",
        "  # Get edge index in terms of the integer indeces assigned to the nodes.\n",
        "  edge_index = load_edge_list(\n",
        "      datafile_path, dz_col, dz_mapping, gene_col, gene_mapping)\n",
        "\n",
        "  # Add the reverse direction (aka make it a undirected graph)\n",
        "  rev_edge_index = load_edge_list(\n",
        "      datafile_path, gene_col, gene_mapping, dz_col, dz_mapping)\n",
        "\n",
        "  # Construct a Data object.\n",
        "  data = Data()\n",
        "  data.num_nodes = len(dz_mapping) + len(gene_mapping)\n",
        "  data.edge_index = torch.cat((edge_index, rev_edge_index), dim=1)\n",
        "  # pretend we have uniform node features\n",
        "  data.x = torch.ones((data.num_nodes, num_features))\n",
        "\n",
        "  return data, gene_mapping, dz_mapping"
      ],
      "metadata": {
        "id": "PIlq-V01zmHL"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data and construct Data object.\n",
        "data_object, gene_mapping, dz_mapping = initialize_data(data_path)\n",
        "print(data_object)\n",
        "print(\"Number of genes:\", len(gene_mapping))\n",
        "print(\"Number of diseases:\", len(dz_mapping))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yL_wt2mYzsGg",
        "outputId": "5d2d021f-9dd5-46e1-b883-ec3aefade8db"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(num_nodes=7813, edge_index=[2, 42714], x=[7813, 1])\n",
            "Number of genes: 7294\n",
            "Number of diseases: 519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_FEATURES =   20\n",
        "data_object.x = torch.ones((data_object.num_nodes, NUM_FEATURES))\n",
        "print(\"Using dummy embeddings as initial node features.\")\n",
        "print(\"Number of features set to \", NUM_FEATURES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnwBBnitz7KD",
        "outputId": "7a4bb92c-7a34-407d-8c83-fec6ce3fd059"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using dummy embeddings as initial node features.\n",
            "Number of features set to  20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "CqKKX_VI0hcx"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = T.Compose([\n",
        "    T.NormalizeFeatures(),\n",
        "    T.ToDevice(device),\n",
        "    T.RandomLinkSplit(num_val=0.05, num_test=0.15, is_undirected=True,\n",
        "                      split_labels=True, add_negative_train_samples=True),\n",
        "])\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = transform(data_object)\n",
        "print(\"Train Data:\\n\", train_dataset)\n",
        "print(\"Validation Data:\\n\", val_dataset)\n",
        "print(\"Test Data:\\n\", test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EXG39Uj0i1T",
        "outputId": "a851faaa-3e7d-4f95-f549-85d6ca0b022c"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data:\n",
            " Data(num_nodes=7813, edge_index=[2, 34174], x=[7813, 20], pos_edge_label=[17087], pos_edge_label_index=[2, 17087], neg_edge_label=[17087], neg_edge_label_index=[2, 17087])\n",
            "Validation Data:\n",
            " Data(num_nodes=7813, edge_index=[2, 34174], x=[7813, 20], pos_edge_label=[1067], pos_edge_label_index=[2, 1067], neg_edge_label=[1067], neg_edge_label_index=[2, 1067])\n",
            "Test Data:\n",
            " Data(num_nodes=7813, edge_index=[2, 36308], x=[7813, 20], pos_edge_label=[3203], pos_edge_label_index=[2, 3203], neg_edge_label=[3203], neg_edge_label_index=[2, 3203])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "HIDDEN_SIZE = 200\n",
        "OUT_CHANNELS = 20\n",
        "input_size = NUM_FEATURES"
      ],
      "metadata": {
        "id": "ZIwxaLGO8XXJ"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_size, out_channels, dropout):\n",
        "        super(GCNEncoder, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_size, cached=True) # cached only for transductive learning\n",
        "        self.conv2 = GCNConv(hidden_size, out_channels, cached=True) # cached only for transductive learning\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x_temp1 = self.conv1(x, edge_index).relu()\n",
        "        x_temp2 = self.dropout(x_temp1)\n",
        "        return self.conv2(x_temp2, edge_index)\n",
        "\n",
        "\n",
        "gae_model = GAE(GCNEncoder(NUM_FEATURES, HIDDEN_SIZE, OUT_CHANNELS, 0.5))\n",
        "gae_model = gae_model.to(device)\n",
        "    "
      ],
      "metadata": {
        "id": "9OnFwf9c8FU9"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "6ZsBmSGJuVGh"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gae_train(train_data, gae_model, optimizer):\n",
        "    gae_model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = gae_model.encode(train_data.x, train_data.edge_index)\n",
        "    loss = gae_model.recon_loss(z, train_data.pos_edge_label_index.to(device))\n",
        "    loss.backward(retain_graph=True)\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "\n",
        "@torch.no_grad()\n",
        "def gae_test(test_data, gae_model):\n",
        "    gae_model.eval()\n",
        "    z = gae_model.encode(test_data.x, test_data.edge_index)\n",
        "    return gae_model.test(z, test_data.pos_edge_label_index, test_data.neg_edge_label_index)\n"
      ],
      "metadata": {
        "id": "fG8AQrvJ1Cc9"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "test_auc = []\n",
        "test_ap = []\n",
        "train_aucs = []\n",
        "train_aps = []\n",
        "EPOCHS =   40\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(gae_model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    loss = gae_train(train_dataset, gae_model, optimizer)\n",
        "    losses.append(loss)\n",
        "    auc, ap = gae_test(test_dataset, gae_model)\n",
        "    test_auc.append(auc)\n",
        "    test_ap.append(ap)\n",
        "\n",
        "    train_auc, train_ap = gae_test(train_dataset, gae_model)\n",
        "\n",
        "    train_aucs.append(train_auc)\n",
        "    train_aps.append(train_ap)\n",
        "\n",
        "    print('Epoch: {:03d}, test AUC: {:.4f}, test AP: {:.4f}, train AUC: {:.4f}, train AP: {:.4f}, loss:{:.4f}'.format(epoch, auc, ap, train_auc, train_ap, loss))"
      ],
      "metadata": {
        "id": "eGnwdkwr3HWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_training_stats(title, losses, test_auc, test_ap, train_auc, train_ap):\n",
        "  \"\"\"Plots evolution of loss and metrics during training\n",
        "\n",
        "  Args: losses, test_auc, test_ap, train_auc, and train_ap should be lists\n",
        "    outputted by the training process.\n",
        "  \"\"\"\n",
        "  fig, ax = plt.subplots()\n",
        "  ax2 = ax.twinx()\n",
        "\n",
        "  ax.set_xlabel(\"Training Epochs\")\n",
        "  ax2.set_ylabel(\"Performance Metric\")\n",
        "  ax.set_ylabel(\"Loss\")\n",
        "\n",
        "  plt.title(title)\n",
        "  p1, = ax.plot(losses, \"b-\", label=\"training loss\")\n",
        "  p2, = ax2.plot(test_auc, \"r-\", label=\"test AUC\")\n",
        "  p3, = ax2.plot(test_ap, \"g-\", label=\"test AP\")\n",
        "  p4, = ax2.plot(train_auc, \"o-\", label=\"train AUC\")\n",
        "  p5, = ax2.plot(train_ap, \"v-\", label=\"train AP\")\n",
        "  plt.legend(handles=[p1, p2, p3, p4, p5])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "YjjW4x0K4Pty"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_stats('GAE', losses, test_auc, test_ap, train_aucs, train_aps)"
      ],
      "metadata": {
        "id": "mEd1dwFx3utl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "def plot_roc_curve(model, data):\n",
        "  \"\"\"Visualizes ROC curve of model predictions\n",
        "\n",
        "  Args: model, pass in the trained or untrained model\n",
        "        data, Data object, where we assume the first 519 datapoints are disease\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "\n",
        "  x = data.x\n",
        "  z = model.encode(x, data.edge_index)\n",
        "\n",
        "  pos_preds = model.decode(z, data.pos_edge_label_index, sigmoid=True)\n",
        "  neg_preds = model.decode(z, data.neg_edge_label_index, sigmoid=True)\n",
        "  preds = torch.cat([pos_preds, neg_preds], dim=0)\n",
        "  preds = preds.detach().cpu().numpy()\n",
        "\n",
        "  labels = torch.cat((data.pos_edge_label, data.neg_edge_label), dim=0)\n",
        "  labels = labels.detach().cpu().numpy()\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(labels, preds)\n",
        "\n",
        "  # Using J-statistic: https://en.wikipedia.org/wiki/Youden%27s_J_statistic\n",
        "  J = tpr - fpr\n",
        "  ix = np.argmax(J)\n",
        "  best_thresh = thresholds[ix]\n",
        "  print('Best Threshold=%f' % (best_thresh))\n",
        "\n",
        "  roc_auc = metrics.roc_auc_score(labels, preds)\n",
        "\n",
        "  plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "  plt.plot([0, 1], [0, 1],'r--') # diagonal roc curve of a random classifier\n",
        "  plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best=%0.2f' % best_thresh)\n",
        "  plt.xlim(0, 1)\n",
        "  plt.ylim(0, 1)\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.legend(loc = 'lower right')\n",
        "  plt.title('ROC curve for model predictions')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "a8TQTUCE7PEq"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_roc_curve(gae_model, test_dataset)"
      ],
      "metadata": {
        "id": "NsI8Jf_Y7irW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}